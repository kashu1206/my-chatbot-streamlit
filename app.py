import base64
import streamlit as st
import time
import google.generativeai as genai
import io
import os
import json

# GCP Speech-to-Text and Text-to-Speech clients
from google.cloud import speech_v1p1beta1 as speech
from google.cloud import texttospeech
from google.oauth2 import service_account

# VAD (Voice Activity Detection) libraries
from pydub import AudioSegment
from pydub.silence import detect_nonsilent

try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    st.error("`streamlit-mic_recorder` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install streamlit-mic-recorder` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    mic_recorder = None

# --- 0. ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---

# Gemini API Key
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=gemini_api_key)
except KeyError:
    st.error("Error: GEMINI_API_KEY is not set in Streamlit Secrets.")
    st.stop() # Gemini APIã‚­ãƒ¼ãŒãªã‘ã‚Œã°ã‚¢ãƒ—ãƒªã‚’åœæ­¢

# GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–å¤‰æ•°ã‚’å®šç¾©
_tts_client = None
_stt_client = None
_can_use_gcp_voice = False
_decoded_gcp_credentials_json_string = None # èªè¨¼æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹å¤‰æ•°

try:
    # Secretsã‹ã‚‰GCPèªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€å„ªå…ˆé †ä½ã‚’è¨­å®š
    # 1. Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±
    if "GCP_CREDENTIALS_BASE64" in st.secrets:
        encoded_credentials = st.secrets["GCP_CREDENTIALS_BASE64"]
        _decoded_gcp_credentials_json_string = base64.b64decode(encoded_credentials.encode("utf-8")).decode("utf-8")

    # 2. ç›´æ¥JSONæ–‡å­—åˆ—ã¨ã—ã¦è¨­å®šã•ã‚ŒãŸèªè¨¼æƒ…å ±
    elif "GCP_CREDENTIALS" in st.secrets:
        raw_credentials = st.secrets["GCP_CREDENTIALS"]
        if isinstance(raw_credentials, dict):
            _decoded_gcp_credentials_json_string = json.dumps(raw_credentials)
        else:
            _decoded_gcp_credentials_json_string = raw_credentials
    
    # 3. ä»¥å‰ã® `GCP_SERVICE_ACCOUNT_KEY` ã¨ã®äº’æ›æ€§ã®ãŸã‚
    elif "GCP_SERVICE_ACCOUNT_KEY" in st.secrets:
        gcp_service_account_key_json = st.secrets.get("GCP_SERVICE_ACCOUNT_KEY")
        if gcp_service_account_key_json:
            service_account_info = json.loads(gcp_service_account_key_json)
            _decoded_gcp_credentials_json_string = json.dumps(service_account_info)
            st.sidebar.success("GCP Credentials loaded successfully from GCP_SERVICE_ACCOUNT_KEY (legacy).")

    # èªè¨¼æƒ…å ±ãŒSecretsã«è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼ã‚’è©¦ã¿ã‚‹
    else:
        st.sidebar.warning("Warning: GCP credentials (GCP_CREDENTIALS_BASE64, GCP_CREDENTIALS, or GCP_SERVICE_ACCOUNT_KEY) not found in Streamlit Secrets. Attempting default credentials.")
        try:
            _tts_client = texttospeech.TextToSpeechClient()
            _stt_client = speech.SpeechClient()
            _can_use_gcp_voice = True
            st.sidebar.info("GCP clients initialized with default credentials.")
        except Exception as e:
            st.sidebar.error(f"Failed to initialize GCP clients with default credentials: {e}")
            _can_use_gcp_voice = False
        
    # èª­ã¿è¾¼ã‚“ã èªè¨¼æƒ…å ±æ–‡å­—åˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ã€GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    if _decoded_gcp_credentials_json_string:
        _gcp_credentials_info = json.loads(_decoded_gcp_credentials_json_string)
        credentials = service_account.Credentials.from_service_account_info(_gcp_credentials_info)
        
        # GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° _stt_client ã¨ _tts_client ã‚’ä½¿ç”¨ï¼‰
        _stt_client = speech.SpeechClient(credentials=credentials)
        _tts_client = texttospeech.TextToSpeechClient(credentials=credentials)
        _can_use_gcp_voice = True
        st.sidebar.info("GCP Speech-to-Text and Text-to-Speech clients initialized from secrets.")

except json.JSONDecodeError as e:
    st.sidebar.error(f"Error decoding GCP credentials JSON: {e}. Please check your Secret format.")
    _can_use_gcp_voice = False
except Exception as e:
    st.sidebar.error(f"Critical error during GCP client setup: {e}")
    _can_use_gcp_voice = False

if not _can_use_gcp_voice:
    st.warning("Voice input/output will not be available due to GCP client initialization failure.")

# --- éŸ³å£°å‡¦ç† (ç„¡éŸ³æ¤œå‡ºãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°) ã®è¨­å®š ---
SAMPLE_RATE = 16000  # Streamlit mic recorder ã¯é€šå¸¸16kHzã§éŒ²éŸ³ã•ã‚Œã‚‹ (GCP Speech-to-Textã®æ¨å¥¨)

# --- éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ (Speech-to-Text) ---
def transcribe_audio_gcp(audio_bytes):
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹å†ç¢ºèª
    if _stt_client is None:
        st.error("Speech-to-Text client is not initialized. Cannot transcribe audio.")
        return ""

    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
        
        if audio_segment.frame_rate != SAMPLE_RATE or audio_segment.channels != 1:
            audio_segment = audio_segment.set_frame_rate(SAMPLE_RATE).set_channels(1)
        
        nonsilent_chunks = detect_nonsilent(audio_segment, 
                                            min_silence_len=500,
                                            silence_thresh=-35)

        if not nonsilent_chunks:
            st.info("No substantial speech detected after trimming.")
            return ""

        trimmed_audio = AudioSegment.empty()
        for start_ms, end_ms in nonsilent_chunks:
            trimmed_audio += audio_segment[start_ms:end_ms]

        # st.info(f"Original audio duration: {len(audio_segment)/1000:.2f}s, Trimmed audio duration: {len(trimmed_audio)/1000:.2f}s")

        # pydub.AudioSegment ã®ã‚µãƒ³ãƒ—ãƒ«å¹…ã‚’16-bit (2ãƒã‚¤ãƒˆ) ã«è¨­å®š
        trimmed_audio = trimmed_audio.set_sample_width(2)

        # â˜…ä¿®æ­£: export() ã®æ›¸ãæ–¹â˜…
        output_buffer = io.BytesIO()
        trimmed_audio.export(output_buffer, format="wav")
        trimmed_audio_bytes = output_buffer.getvalue()

        audio = speech.RecognitionAudio(content=trimmed_audio_bytes)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=SAMPLE_RATE,
            language_code="en-US",
            enable_automatic_punctuation=True,
        )

        response = _stt_client.recognize(config=config, audio=audio)
        transcript = ""
        for result in response.results:
            transcript += result.alternatives[0].transcript
        return transcript
    except Exception as e:
        st.error(f"Error transcribing audio with Google Cloud Speech-to-Text API: {e}")
        return ""

# --- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã¸ (Text-to-Speech) ---
def synthesize_text_gcp(text):
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹å†ç¢ºèª
    if _tts_client is None:
        st.error("Text-to-Speech client is not initialized. Cannot synthesize speech.")
        return None

    try:
        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="en-US",
            name="en-US-Standard-F",
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.M4A,
            speaking_rate=1.0,
        )

        response = _tts_client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )
        return response.audio_content
    except Exception as e:
        st.error(f"Error synthesizing speech with Google Cloud Text-to-Speech API: {e}")
        return None

# --- Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– ---
@st.cache_resource
def get_gemini_model():
    return genai.GenerativeModel('gemini-flash-latest')
model = get_gemini_model()

# --- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã¨ãƒ¬ãƒ™ãƒ«èª¿æ•´æ©Ÿèƒ½ ---
def get_system_instruction(level):
    # Base instruction common to all levels, explicitly enforcing English responses
    base_instruction = (
    "You are an English conversation partner who helps users improve their English skills. "
    "You are also an experienced English teacher with extensive experience guiding native Japanese speakers in learning English as a foreign language. "
    "Please keep in mind that the user is a native Japanese speaker throughout your interactions. "
    "**Always respond only in English. Do not use Japanese at all.**"
)

    if level == "Hana":
        return base_instruction + (
            " Your name is Tanaka Hana. You are a girl from Wakaba Junior High School, originally from Wakaba City."
            " You have a gentle and meticulous personality, and your friends often consult you when they're in trouble."
            " You've been dedicated to soccer since age 3. Recently, you've been enjoying family camping trips and mastering camp cooking."
            " You're preparing to play in an overseas soccer league after junior high school graduation."
            " Your favorite subject is English, and your hobbies are soccer and baking sweets."
            " You will converse according to the English ability of a Japanese junior high school 1st grader."
            " Focus on basic vocabulary like 'be, have, go, see, eat, school, friend, happy, kind, clean, big, small', targeting a total vocabulary of around 300-1300 words."
            " Speak slowly using very simple words and short sentences (maximum 10 words per sentence)."
            " Ask simple questions to encourage conversation."
            " Keep your responses concise and conversational, ideally around 50 words. Only expand slightly if you need to clarify something briefly."
            " **Do not point out any grammar or spelling mistakes in the user's input. Accept them as they are and continue the conversation.**"
        )
    elif level == "Mark":
        return base_instruction + (
            " Your name is Mark Davis. You are a boy from Wakaba Junior High School, originally from Seattle, USA."
            " You have a cheerful personality and are a mood-maker in class. You have an older sister who is in high school."
            " You love interacting with people and have been entrusted with looking after the new first-year students in your basketball club."
            " While continuing your beloved basketball, you are diligently studying to become a veterinarian."
            " Your favorite subject is Science, and you are very athletic, placing high in the Wakaba Marathon every year."
            " You will converse according to the English ability of a Japanese junior high school graduate (Eiken Grade 3 equivalent)."
            " Use everyday, emotional, and regional vocabulary such as 'enjoy, plan, decide, describe, delicious, exciting, important, healthy, wonderful, popular', targeting a total vocabulary of around 1250-2100 words."
            " Prioritize concise and conversational responses, generally aiming for about 100 words. However, feel free to expand and provide more detail when explaining a concept, sharing an interesting perspective, or offering helpful suggestions related to grammar or vocabulary."
            " **Only if there are obvious grammar or spelling mistakes in the user's input, gently point them out or suggest a more natural way to phrase it, assisting the user to correct them on their own.**"
            " Incorporate slightly longer sentences and somewhat complex sentence structures, focusing on a natural flow of conversation."
        )
    elif level == "Ms. Brown":
        return base_instruction + (
            " Your name is Ms. Lucy Brown. You are an ALT (Assistant Language Teacher) at Wakaba Junior High School, originally from London, UK."
            " You love reading and own many different books. Recently, you've been reading a lot of Japanese novels."
            " When you were a junior high school student, your dream was to be a novelist, and you often wrote novels based on everyday events."
            " You love houseplants and animals."
            " You will converse in a sophisticated and natural English style, appropriate for an English teacher, but always keeping in mind that your user is a Japanese junior high school student." # ã“ã“ã‚’ä¿®æ­£
            " Your responses should be clear, engaging, and aim to gently expand their vocabulary and grammatical understanding without being overwhelming." # ã“ã“ã‚’ä¿®æ­£
            " While you may introduce new, slightly more advanced words or expressions, ensure they are understandable through context or by providing simple explanations if necessary." # ã“ã“ã‚’è¿½åŠ 
            " Avoid overly academic, abstract, or highly specialized vocabulary that would be far beyond a typical junior high school student's comprehension without significant explanation." # ã“ã“ã‚’è¿½åŠ 
            " While your default should be a natural, conversational length to foster dynamic exchange, you are encouraged to expand your responses, typically up to around 200 words, when providing detailed explanations of grammar or vocabulary, offering deeper insights, or giving comprehensive feedback to enhance the user's learning."
            " If there are grammar or spelling mistakes in the user's input, **gently point them out or suggest more sophisticated expressions, assisting the user to think and correct them on their own.**"
            " However, your role is primarily a facilitator, encouraging the user's critical thinking and expression. Discuss a wide range of topics deeply and in natural English."
        )
    else: # Default case, though unlikely with selectbox
        return base_instruction + " Use natural, everyday English. Engage in friendly conversation and ask open-ended questions."


# --- Streamlit UIã®æ§‹ç¯‰ ---
st.set_page_config(layout="wide")
st.title("English Conversation Partner ğŸ—£ï¸")
st.write("Let's practice English together!")

with st.sidebar:
    st.header("Settings")
    
    # è‹±èªãƒ¬ãƒ™ãƒ«é¸æŠ
    english_level = st.selectbox(
        "Select your English Level:",
        [
            "Hana",
            "Mark",
            "Ms. Brown"
        ],
        index=0,
        key="english_level_selector"
    )

    # éŸ³å£°å…¥åŠ›/å‡ºåŠ›ã®ON/OFFãƒˆã‚°ãƒ« (GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã§ããŸå ´åˆã®ã¿æœ‰åŠ¹)
    use_audio_io = st.toggle("éŸ³å£°å…¥å‡ºåŠ›", value=False, key="audio_io_toggle", disabled=not _can_use_gcp_voice)

    if use_audio_io and (mic_recorder is None or not _can_use_gcp_voice): # mic_recorderã®åˆ©ç”¨å¯èƒ½æ€§ã¨GCPéŸ³å£°åˆ©ç”¨å¯èƒ½æ€§ã®ä¸¡æ–¹ã‚’ç¢ºèª
        st.warning("éŸ³å£°å…¥å‡ºåŠ›ã¯ã€`streamlit-mic-recorder` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã‚‹ã‹ã€GCPèªè¨¼æƒ…å ±ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ç„¡åŠ¹ã§ã™ã€‚")

# --- ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– (ãƒ¬ãƒ™ãƒ«é¸æŠã«å¿œã˜ã¦ system_instruction ã‚’è¨­å®š) ---
current_system_instruction = get_system_instruction(english_level)
model = genai.GenerativeModel(
    'gemini-flash-latest',
    system_instruction=current_system_instruction
)

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Streamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.previous_english_level = english_level # Initialize previous_english_level
    # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    initial_message = ""
    if english_level == "Hana":
        initial_message = "Hi! I'm Tanaka Hana. What would you like to talk about today?"
    elif english_level == "Mark":
        initial_message = "Hey there! I'm Mark. What's up?"
    elif english_level == "Ms. Brown":
        initial_message = "Good day! I'm Ms. Brown. How may I assist you today?"
    st.session_state.messages.append({"role": "assistant", "content": initial_message})

    # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®éŸ³å£°å†ç”Ÿ
    if use_audio_io and _can_use_gcp_voice and initial_message:
        audio_output = synthesize_text_gcp(initial_message)
        if audio_output:
            st.audio(audio_output, format="audio/mp4", autoplay=True)


if st.session_state.get("previous_english_level") != english_level:
    st.session_state.messages = []
    # Dynamic initial message after level change
    initial_message = "Hello! Let's start our conversation. What's on your mind today?"
    if english_level == "Hana":
        initial_message = "Hi! I'm Tanaka Hana. What would you like to talk about today?"
    elif english_level == "Mark":
        initial_message = "Hey there! I'm Mark. What's up?"
    elif english_level == "Ms. Brown":
        initial_message = "Good day! I'm Ms. Brown. How may I assist you today?"

    system_change_message = f"Okay, switching to the {english_level} . {initial_message}"
    st.session_state.messages.append({"role": "assistant", "content": system_change_message})
    st.session_state.previous_english_level = english_level

    # ãƒ¬ãƒ™ãƒ«å¤‰æ›´æ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®éŸ³å£°å†ç”Ÿ
    if use_audio_io and _can_use_gcp_voice and system_change_message:
        audio_output = synthesize_text_gcp(system_change_message)
        if audio_output:
            st.audio(audio_output, format="audio/mp4", autoplay=True)

# --- æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹ ---
user_input_from_mic = ""   # ãƒã‚¤ã‚¯ã‹ã‚‰ã®å…¥åŠ›çµæœã‚’ä¿æŒã™ã‚‹å¤‰æ•°
user_input_from_text = ""  # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®çµæœã‚’ä¿æŒã™ã‚‹å¤‰æ•°
final_user_input_prompt = "" # æœ€çµ‚çš„ã«Geminiã«é€ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

if use_audio_io:
    st.write("Click the mic and speak!")
    audio_bytes = None
    if mic_recorder: # mic_recorder ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        recorded_audio = mic_recorder(
            start_prompt="ğŸ¤ éŒ²éŸ³é–‹å§‹",
            stop_prompt="â¹ï¸ éŒ²éŸ³åœæ­¢",
            just_once=True,
            use_container_width=True,
            key='user_mic_input'
        )
        if recorded_audio:
            audio_bytes = recorded_audio['bytes']

    if audio_bytes and _can_use_gcp_voice:
        with st.spinner("Processing audio and transcribing..."):
            user_input_from_mic = transcribe_audio_gcp(audio_bytes)
            # if user_input_from_mic:
                # st.write(f"You said: {user_input_from_mic}")
            else:
                st.warning("Could not transcribe audio. Please try speaking clearer, or use text input below.")
    elif audio_bytes and not _can_use_gcp_voice: # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ãŒGCPãŒä½¿ãˆãªã„å ´åˆ
        st.warning("GCP voice services are not enabled. Cannot transcribe recorded audio.")

    # ãƒã‚¤ã‚¯ã‹ã‚‰ã®å…¥åŠ›ãŒã‚ã£ãŸã‹ã©ã†ã‹ã«ã‹ã‹ã‚ã‚‰ãšã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã¯å¸¸ã«è¡¨ç¤ºãƒ»æœ‰åŠ¹
    # ã“ã“ã§ã® disabled ã¯å¸¸ã« False ã¨ãªã‚‹
    user_input_from_text = st.chat_input("Start practicing English with me! (Type here)")

    # æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’æ±ºå®šï¼šãƒã‚¤ã‚¯ã‹ã‚‰ã®å…¥åŠ›ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã€ãªã‘ã‚Œã°ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’ä½¿ã†
    if user_input_from_mic:
        final_user_input_prompt = user_input_from_mic
    elif user_input_from_text:
        final_user_input_prompt = user_input_from_text

else: # use_audio_io ãŒ False ã®å ´åˆ (éŸ³å£°å…¥åŠ›ãŒç„¡åŠ¹ãªå ´åˆ)
    final_user_input_prompt = st.chat_input("Start practicing English with me! (Type here)")


if final_user_input_prompt: # â˜…ã“ã“ã‚’ final_user_input_prompt ã«å¤‰æ›´â˜…
    st.session_state.messages.append({"role": "user", "content": final_user_input_prompt}) # â˜…ã“ã“ã‚’ final_user_input_prompt ã«å¤‰æ›´â˜…
    with st.chat_message("user"):
        st.markdown(final_user_input_prompt) # â˜…ã“ã“ã‚’ final_user_input_prompt ã«å¤‰æ›´â˜…

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        gemini_chat_history = []
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                gemini_chat_history.append({"role": "user", "parts": [msg["content"]]})
            elif msg["role"] == "assistant":
                # ãƒ¬ãƒ™ãƒ«å¤‰æ›´æ™‚ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å±¥æ­´ã«å«ã‚ãªã„
                if "Okay, switching to the " not in msg["content"]:
                    gemini_chat_history.append({"role": "model", "parts": [msg["content"]]})

        chat = model.start_chat(history=gemini_chat_history)

        try:
            response_generator = chat.send_message(final_user_input_prompt, stream=True) # â˜…ã“ã“ã‚’ final_user_input_prompt ã«å¤‰æ›´â˜…

            for chunk in response_generator:
                full_response += chunk.text
                message_placeholder.markdown(full_response + "â–Œ")
                time.sleep(0.05)
            message_placeholder.markdown(full_response)

            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # Assistantã®è¿”ç­”ã‚’éŸ³å£°ã§å†ç”Ÿ
            if use_audio_io and _can_use_gcp_voice and full_response:
                audio_output = synthesize_text_gcp(full_response)
                if audio_output:
                    st.audio(audio_output, format="audio/mp4", autoplay=True)

        except Exception as e:
            st.error(f"An error occurred with Gemini: {e}. Please try again.")
            st.session_state.messages.append({"role": "assistant", "content": f"An error occurred with Gemini: {e}. Please try again."})